name: AI Build and Deploy (Self-Hosted)

on:
   push:
      branches: [main, master]
      paths:
         - 'AI/**'

jobs:
   build-and-deploy:
      runs-on: self-hosted
      permissions:
         contents: read

      steps:
         # 1ï¸âƒ£ Checkout repository
         - name: 1. Checkout repository
           uses: actions/checkout@v4

         # 2ï¸âƒ£ Verify directory layout
         - name: 2. Verify directory layout
           working-directory: .
           run: |
              echo "Workspace content:"
              pwd
              ls
              echo ""
              echo "AI contents:"
              ls AI
              test -f AI/docker-compose.yml

         # 3ï¸âƒ£ Setup Docker Buildx
         - name: 3. Set up Docker Buildx
           uses: docker/setup-buildx-action@v3

         # 4ï¸âƒ£ Pull latest Ollama base images
         - name: 4. Pull latest Ollama base images
           run: |
              docker pull ollama/ollama:latest

         # 5ï¸âƒ£ Verify GPU support
         - name: 5. Verify GPU support
           run: |
              echo "Checking NVIDIA GPU availability..."
              nvidia-smi || echo "Warning: nvidia-smi not available"
              echo "Checking Docker GPU support..."
              docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi || echo "Warning: Docker GPU support may not be configured"

         # 6ï¸âƒ£ Remove old container (required because container_name is fixed)
         - name: 6. Remove old container
           working-directory: AI
           run: |
              docker rm -f ollama || true

         # 7ï¸âƒ£ Stop current deployment
         - name: 7. Stop current deployment
           working-directory: AI
           run: |
              docker compose down || true

         # 8ï¸âƒ£ Deploy new version
         - name: 8. Deploy new version
           working-directory: AI
           run: |
              docker compose up -d --build --pull always

         # 9ï¸âƒ£ Verify deployment health
         - name: 9. Verify deployment health
           working-directory: AI
           run: |
              echo "Waiting for Ollama health check..."
              for i in {1..10}; do
                if curl -fsS http://localhost:11434/api/tags > /dev/null 2>&1; then
                  echo "Ollama is healthy"
                  echo "Available models:"
                  curl -s http://localhost:11434/api/tags | grep -o '"name":"[^"]*"' || echo "No models installed yet"
                  exit 0
                fi
                echo "Attempt $i/10 failed, retrying..."
                sleep 3
              done
              echo "Service failed health check"
              docker compose logs
              exit 1

         # ðŸ”Ÿ Show logs on failure
         - name: 10. Show logs on failure
           if: failure()
           working-directory: AI
           run: docker compose logs
